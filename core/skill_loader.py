import os
import re
import json
from dataclasses import dataclass
from typing import Dict, Optional, Any
from openai import AsyncOpenAI

# å¼•å…¥ä½ çš„ç»Ÿä¸€é…ç½®
try:
    import config
except ImportError:
    # ç®€å•çš„å…œåº•ï¼Œé˜²æ­¢ IDE æŠ¥é”™
    class ConfigMock:
        SKILLS_DIR = "skills"
        LLM_API_KEY = ""
        LLM_BASE_URL = ""
    config = ConfigMock()

@dataclass
class SkillConfig:
    """Skill é…ç½®æ•°æ®ç»“æ„"""
    name: str
    description: str
    model: str
    temperature: float
    max_tokens: int
    response_format: Optional[dict] # æ–°å¢ï¼šæ”¯æŒå®šä¹‰è¿”å›æ ¼å¼(json_object)
    system_prompt: str
    user_prompt_template: str

    def render_prompt(self, **kwargs) -> str:
        """æ¸²æŸ“ User Promptï¼Œå¡«å……å˜é‡"""
        try:
            result = self.user_prompt_template
            # æŒ‰é•¿åº¦é™åºæ’åºï¼Œé¿å…çŸ­å˜é‡åå¹²æ‰° (å¦‚ {a} å’Œ {abc})
            sorted_items = sorted(kwargs.items(), key=lambda x: len(x[0]), reverse=True)
            for key, value in sorted_items:
                # ç®€å•è½¬ä¹‰å¤„ç†ï¼Œé˜²æ­¢æ³¨å…¥
                val_str = json.dumps(value, ensure_ascii=False) if isinstance(value, (dict, list)) else str(value)
                # å¦‚æœæ˜¯ç®€å•å­—ç¬¦ä¸²ï¼Œå»æ‰é¦–å°¾å¼•å·ï¼Œçœ‹èµ·æ¥æ›´è‡ªç„¶
                if isinstance(value, str):
                    val_str = value
                
                placeholder = "{" + key + "}"
                if placeholder in result:
                    result = result.replace(placeholder, val_str)
            return result
        except Exception as e:
            raise ValueError(f"Prompt æ¸²æŸ“é”™è¯¯: {e}")

class SkillLoader:
    """
    å…¨èƒ½ Skill åŠ è½½ä¸æ‰§è¡Œå™¨
    è´Ÿè´£ï¼šè¯»å– Markdown -> è§£æé…ç½® -> è°ƒç”¨ LLM -> è¿”å›ç»“æœ
    """
    
    def __init__(self, api_key: str = None, base_url: str = None):
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä½¿ç”¨ config
        self.api_key = api_key or getattr(config, 'LLM_API_KEY', None)
        self.base_url = base_url or getattr(config, 'LLM_BASE_URL', None)
        
        if not self.api_key:
            raise ValueError("æœªé…ç½® API Keyï¼Œè¯·æ£€æŸ¥ config.py æˆ–ä¼ å…¥å‚æ•°")

        self.client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)

    async def execute_skill(self, skill_file: str, inputs: Dict[str, Any]) -> Dict:
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šæ‰§è¡Œä¸€ä¸ª Skill
        :param skill_file: skill æ–‡ä»¶å (å¦‚ 'rewrite.md')
        :param inputs: å¡«å…… Prompt çš„å˜é‡å­—å…¸
        :return: LLM è¿”å›çš„å­—å…¸ (å¦‚æœæ˜¯ JSON) æˆ–åŒ…å« content çš„å­—å…¸
        """
        # 1. ç¡®å®šæ–‡ä»¶è·¯å¾„
        # å¦‚æœä¼ å…¥çš„æ˜¯ç»å¯¹è·¯å¾„å°±ç”¨ç»å¯¹è·¯å¾„ï¼Œå¦åˆ™å» config.SKILLS_DIR æ‰¾
        if os.path.isabs(skill_file):
            file_path = skill_file
        else:
            file_path = os.path.join(getattr(config, 'SKILLS_DIR', 'skills'), skill_file)

        # 2. åŠ è½½å¹¶è§£æ Markdown
        skill_config = self._load_markdown(file_path)

        # 3. æ¸²æŸ“ User Prompt
        user_msg = skill_config.render_prompt(**inputs)

        # 4. è°ƒç”¨ LLM
        # print(f"ğŸš€ [Skill] Executing: {skill_config.name} ({skill_config.model})") 
        try:
            response = await self.client.chat.completions.create(
                model=skill_config.model,
                messages=[
                    {"role": "system", "content": skill_config.system_prompt},
                    {"role": "user", "content": user_msg}
                ],
                temperature=skill_config.temperature,
                max_tokens=skill_config.max_tokens,
                response_format=skill_config.response_format
            )

            content = response.choices[0].message.content
            
            # 5. ç»“æœå¤„ç† (å°è¯•è§£æ JSON)
            # å¦‚æœé…ç½®é‡Œè¦æ±‚äº† json_objectï¼Œæˆ–è€…å†…å®¹çœ‹èµ·æ¥åƒ JSON
            if skill_config.response_format and skill_config.response_format.get('type') == 'json_object':
                try:
                    return json.loads(content)
                except json.JSONDecodeError:
                    print(f"âš ï¸ [Warning] LLM è¿”å›çš„ä¸æ˜¯æœ‰æ•ˆ JSON: {content[:50]}...")
                    return {"raw_content": content, "error": "json_parse_fail"}
            else:
                return {"content": content}

        except Exception as e:
            print(f"âŒ Skill Execution Failed [{skill_file}]: {e}")
            # è¿”å›ç©ºå­—å…¸æˆ–é”™è¯¯ä¿¡æ¯ï¼Œé˜²æ­¢ä¸»ç¨‹åºå´©æºƒ
            return {"error": str(e)}

    def _load_markdown(self, md_path: str) -> SkillConfig:
        """å†…éƒ¨æ–¹æ³•ï¼šè¯»å–å¹¶è§£æ Markdown æ–‡ä»¶"""
        if not os.path.exists(md_path):
            raise FileNotFoundError(f"Skill file not found: {md_path}")

        with open(md_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # è§£æå¤´éƒ¨å…ƒæ•°æ®
        meta = self._parse_front_matter(content)
        
        # å¤„ç† Response Format (æ”¯æŒåœ¨ md å¤´éƒ¨å†™ "ResponseFormat: json_object")
        resp_format = None
        if meta.get('responseformat') == 'json_object':
            resp_format = {"type": "json_object"}

        # æå– Prompts
        system_prompt = self._extract_section(content, "System Prompt")
        user_template = self._extract_section(content, "User Prompt Template")

        if not system_prompt or not user_template:
            raise ValueError(f"Invalid skill file: {md_path}. ç¼ºå°‘ System Prompt æˆ– User Prompt Template ç« èŠ‚ã€‚")

        return SkillConfig(
            name=meta.get('name', 'unknown_skill'),
            description=meta.get('description', ''),
            model=meta.get('model', getattr(config, 'LLM_MODEL_NAME', 'deepseek-chat')),
            temperature=float(meta.get('temperature', getattr(config, 'AGENT_TEMPERATURE', 0.1))),
            max_tokens=int(meta.get('maxtokens', 2000)),
            response_format=resp_format,
            system_prompt=system_prompt,
            user_prompt_template=user_template
        )

    @staticmethod
    def _parse_front_matter(content: str) -> Dict[str, str]:
        """è§£æ # Key: Value"""
        meta = {}
        for line in content.split('\n'):
            line = line.strip()
            if not line: continue
            if not line.startswith('#'): break # ç¢°åˆ°éæ³¨é‡Šè¡Œåœæ­¢
            
            # å»æ‰å¼€å¤´çš„ # 
            content_line = line[1:].strip()
            if ':' in content_line:
                key, value = content_line.split(':', 1)
                meta[key.strip().lower().replace('_', '')] = value.strip()
        return meta

    @staticmethod
    def _extract_section(content: str, section_name: str) -> Optional[str]:
        """æå– ## Section ä¸‹çš„å†…å®¹"""
        # åŒ¹é… ## SectionName åˆ°ä¸‹ä¸€ä¸ª ## æˆ–æ–‡ä»¶ç»“æŸ
        pattern = rf'## {section_name}\s*\n(.*?)(?=\n## |\Z)'
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1).strip() if match else None